"""
ì§ˆë³‘ê´€ë¦¬ì²­ ê°ì—¼ë³‘ ë°ì´í„° UTF-8 ì¸ì½”ë”© ë³€í™˜ê¸°
ì‹¤ì œ CSV íŒŒì¼ë“¤ì„ í•œê¸€ í—¤ë”ì™€ í•¨ê»˜ ê¹”ë”í•œ UTF-8 í˜•íƒœë¡œ ë³€í™˜
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path

class KDCAEncodingFixer:
    def __init__(self):
        """ì´ˆê¸°í™” ë° í•œê¸€ ë§¤í•‘ ì„¤ì •"""
        os.makedirs('data/kdca', exist_ok=True)
        os.makedirs('raw_data/kdca', exist_ok=True)
        
        # ì§€ì—­ëª… ë§¤í•‘ (ìº¡ì²˜ ì´ë¯¸ì§€ ê¸°ì¤€)
        self.regions = [
            'ì „êµ­', 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°',
            'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼', 'ì„¸ì¢…'
        ]
        
        # ê°ì—¼ë³‘ ì»¬ëŸ¼ëª… (ìº¡ì²˜ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ë§¤í•‘)
        self.disease_columns = [
            # ì œ1ê¸‰ ê°ì—¼ë³‘
            'ì—ë³¼ë¼ë°”ì´ëŸ¬ìŠ¤ë³‘', 'ë§ˆë²„ê·¸ì—´', 'ë¼ì‚¬ì—´', 'í¬ë¦¬ë¯¸ì•ˆì½©ê³ ì¶œí˜ˆì—´', 'ë‚¨ì•„ë©”ë¦¬ì¹´ì¶œí˜ˆì—´',
            'ë¦¬í”„íŠ¸ë°¸ë¦¬ì—´', 'ë‘ì°½', 'í˜ìŠ¤íŠ¸', 'íƒ„ì €', 'ë³´íˆ´ë¦¬ëˆ”ë…ì†Œì¦', 'ì•¼í† ë³‘',
            'ì‹ ì¢…í˜¸í¡ê¸°ì¦í›„êµ°', 'ì¤‘ë™í˜¸í¡ê¸°ì¦í›„êµ°', 'ë™ë¬¼ì¸í”Œë£¨ì—”ìì¸ì²´ê°ì—¼ì¦', 'ì‹ ì¢…ì¸í”Œë£¨ì—”ì',
            'ë””í”„í…Œë¦¬ì•„', 'ìˆ˜ë‘',
            
            # ì œ2ê¸‰ ê°ì—¼ë³‘  
            'í™ì—­', 'ì½œë ˆë¼', 'ì¥í‹°í‘¸ìŠ¤', 'íŒŒë¼í‹°í‘¸ìŠ¤', 'ì„¸ê· ì„±ì´ì§ˆ', 'ì¥ì¶œí˜ˆì„±ëŒ€ì¥ê· ê°ì—¼ì¦',
            'Aí˜•ê°„ì—¼', 'ë°±ì¼í•´', 'ìœ í–‰ì„±ì´í•˜ì„ ì—¼', 'í’ì§„', 'í´ë¦¬ì˜¤', 'ìˆ˜ë§‰êµ¬ê· ê°ì—¼ì¦',
            'í—¤ëª¨í•„ë£¨ìŠ¤ì¸í”Œë£¨ì—”ìê· ê°ì—¼ì¦', 'íë ´êµ¬ê· ê°ì—¼ì¦', 'í•œì„¼ë³‘', 'ì„±í™ì—´',
            'ë°˜ì½”ë§ˆì´ì‹ ë‚´ì„±í™©ìƒ‰í¬ë„ì•Œê· (VRSA)ê°ì—¼ì¦', 'ì¹´ë°”í˜ë„´ë‚´ì„±ì¥ë‚´ì„¸ê· ì†ê· ì¢…(CRE)ê°ì—¼ì¦',
            
            # ì œ3ê¸‰ ê°ì—¼ë³‘
            'ê²°í•µ', 'ë§ë¼ë¦¬ì•„', 'ë ˆì§€ì˜¤ë„¬ë¼ì¦', 'ë¹„ë¸Œë¦¬ì˜¤íŒ¨í˜ˆì¦', 'ë°œì§„ì—´', 'ë°œì§„í‹°í‘¸ìŠ¤',
            'ì¯”ì¯”ê°€ë¬´ì‹œì¦', 'ë ™í† ìŠ¤í”¼ë¼ì¦', 'ë¸Œë£¨ì…€ë¼ì¦', 'ê³µìˆ˜ë³‘', 'ì‹ ì¦í›„êµ°ì¶œí˜ˆì—´',
            'í›„ì²œì„±ë©´ì—­ê²°í•ì¦(AIDS)', 'ë§¤ë…', 'í¬ë¡œì´ì¸ í íŠ¸-ì•¼ì½¥ë³‘(CJD)', 'í™©ì—´', 'ë…ê¸°ì—´',
            'ì›¨ìŠ¤íŠ¸ë‚˜ì¼ì—´', 'ë¼ì„ë³‘', 'ì§„ë“œê¸°ë§¤ê°œë‡Œì—¼', 'ìœ ë¹„ì €', 'ì¹˜ì¿¤êµ¬ë‹ˆì•¼ì—´'
        ]
        
        print("âœ… ì§ˆë³‘ê´€ë¦¬ì²­ ì¸ì½”ë”© ë³€í™˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“ ì§€ì—­: {len(self.regions)}ê°œ")
        print(f"ğŸ“Š ê°ì—¼ë³‘: {len(self.disease_columns)}ê°œ")
    
    def read_broken_csv(self, filepath):
        """ì¸ì½”ë”©ì´ ê¹¨ì§„ CSV íŒŒì¼ ì½ê¸°"""
        encodings = ['euc-kr', 'cp949', 'utf-8', 'latin-1']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(filepath, encoding=encoding, header=None)
                print(f"âœ… {encoding}ë¡œ ì½ê¸° ì„±ê³µ: {filepath}")
                return df
            except Exception as e:
                continue
        
        print(f"âŒ ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨: {filepath}")
        return None
    
    def convert_to_utf8_with_headers(self, filepath, year):
        """ê¹¨ì§„ CSVë¥¼ í•œê¸€ í—¤ë”ê°€ ìˆëŠ” UTF-8 CSVë¡œ ë³€í™˜"""
        print(f"\nğŸ“‹ {year}ë…„ ë°ì´í„° ë³€í™˜ ì¤‘...")
        
        # ì›ë³¸ íŒŒì¼ ì½ê¸°
        df = self.read_broken_csv(filepath)
        if df is None:
            return None
        
        print(f"ì›ë³¸ í¬ê¸°: {df.shape}")
        
        # ìƒˆë¡œìš´ DataFrame ìƒì„± (í•œê¸€ í—¤ë” í¬í•¨)
        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì§€ì—­ëª…, ë‚˜ë¨¸ì§€ëŠ” ê°ì—¼ë³‘ë³„ ë°œìƒê±´ìˆ˜
        
        # ì§€ì—­ ê°œìˆ˜ë§Œí¼ í–‰ í™•ë³´ (ì „êµ­ í¬í•¨ 18ê°œ)
        num_regions = min(len(df), len(self.regions))
        
        # ì»¬ëŸ¼ í—¤ë” ìƒì„±
        headers = ['ì§€ì—­'] + [f'ê°ì—¼ë³‘_{i+1:02d}' for i in range(df.shape[1] - 1)]
        
        # ë°ì´í„° ë³€í™˜
        new_data = []
        for i in range(num_regions):
            row_data = [self.regions[i]]  # ì§€ì—­ëª…
            
            # ìˆ«ì ë°ì´í„° ì¶”ê°€ (ì›ë³¸ 1ë²ˆ ì»¬ëŸ¼ë¶€í„°)
            if i < len(df):
                original_row = df.iloc[i]
                for j in range(1, len(original_row)):
                    try:
                        val = float(original_row.iloc[j]) if pd.notna(original_row.iloc[j]) else 0
                        row_data.append(int(val) if val >= 0 else 0)
                    except:
                        row_data.append(0)
            
            new_data.append(row_data)
        
        # ìƒˆë¡œìš´ DataFrame ìƒì„±
        result_df = pd.DataFrame(new_data, columns=headers)
        
        # UTF-8ë¡œ ì €ì¥
        output_path = f'data/kdca/{year}_ê°ì—¼ë³‘_UTF8.csv'
        result_df.to_csv(output_path, index=False, encoding='utf-8')
        
        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {output_path}")
        print(f"ìƒˆ í¬ê¸°: {result_df.shape}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        if len(result_df) > 0:
            print(f"ìƒ˜í”Œ: {result_df.iloc[1]['ì§€ì—­']} = {result_df.iloc[1, 17:22].sum():.0f}ê±´")
        
        return result_df
    
    def convert_all_years(self):
        """ì „ì²´ ì—°ë„ ë°ì´í„° ë³€í™˜"""
        print("ğŸš€ 2019-2024ë…„ ì „ì²´ ë°ì´í„° UTF-8 ë³€í™˜ ì‹œì‘")
        print("=" * 60)
        
        years = [2019, 2020, 2021, 2022, 2023, 2024]
        converted_files = []
        
        for year in years:
            filepath = f'{year}_ì „êµ­_ê°ì—¼ë³‘.csv'
            
            if Path(filepath).exists():
                result_df = self.convert_to_utf8_with_headers(filepath, year)
                if result_df is not None:
                    converted_files.append(f'{year}_ê°ì—¼ë³‘_UTF8.csv')
            else:
                print(f"âŒ íŒŒì¼ ì—†ìŒ: {filepath}")
        
        print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ! ì´ {len(converted_files)}ê°œ íŒŒì¼")
        for filename in converted_files:
            print(f"  ğŸ“ data/kdca/{filename}")
        
        return converted_files
    
    def create_master_dataset(self):
        """í†µí•© ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„±"""
        print("\nğŸ“Š í†µí•© ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        years = [2019, 2020, 2021, 2022, 2023, 2024]
        all_data = []
        
        for year in years:
            filepath = f'data/kdca/{year}_ê°ì—¼ë³‘_UTF8.csv'
            
            if Path(filepath).exists():
                try:
                    df = pd.read_csv(filepath, encoding='utf-8')
                    # ì—°ë„ ì»¬ëŸ¼ ì¶”ê°€
                    df.insert(0, 'ì—°ë„', year)
                    all_data.append(df)
                    print(f"âœ… {year}ë…„ ë°ì´í„° ë¡œë“œ: {df.shape}")
                except Exception as e:
                    print(f"âŒ {year}ë…„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if all_data:
            # ì „ì²´ ë°ì´í„° í†µí•©
            master_df = pd.concat(all_data, ignore_index=True)
            
            # ë§ˆìŠ¤í„° íŒŒì¼ ì €ì¥
            master_df.to_csv('data/kdca/kdca_master_dataset.csv', index=False, encoding='utf-8')
            
            print(f"ğŸ† ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“Š í¬ê¸°: {master_df.shape}")
            print(f"ğŸ“… ê¸°ê°„: 2019-2024ë…„ ({len(years)}ë…„)")
            print(f"ğŸ™ï¸ ì§€ì—­: {len(master_df['ì§€ì—­'].unique())}ê°œ")
            
            # ë¯¸ë¦¬ë³´ê¸°
            print("\nğŸ“‹ ë§ˆìŠ¤í„° ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            print(master_df[['ì—°ë„', 'ì§€ì—­', 'Infection_17', 'Infection_18', 'Infection_19']].head(10))
            
            return master_df
        else:
            print("âŒ í†µí•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
    
    def create_summary_report(self):
        """ë³€í™˜ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ"""
        print("\n" + "=" * 60)
        print("ğŸ† ì§ˆë³‘ê´€ë¦¬ì²­ ë°ì´í„° UTF-8 ë³€í™˜ ì™„ë£Œ ë³´ê³ ì„œ")
        print("=" * 60)
        
        # ë³€í™˜ëœ íŒŒì¼ë“¤ í™•ì¸
        converted_files = []
        years = [2019, 2020, 2021, 2022, 2023, 2024]
        
        for year in years:
            filepath = f'data/kdca/{year}_ê°ì—¼ë³‘_UTF8.csv'
            if Path(filepath).exists():
                file_size = Path(filepath).stat().st_size
                converted_files.append((year, filepath, file_size))
        
        print(f"ğŸ“ ë³€í™˜ëœ íŒŒì¼: {len(converted_files)}ê°œ")
        for year, filepath, size in converted_files:
            print(f"  {year}ë…„: {filepath} ({size:,} bytes)")
        
        # ë§ˆìŠ¤í„° íŒŒì¼ í™•ì¸
        master_path = 'data/kdca/kdca_master_dataset.csv'
        if Path(master_path).exists():
            master_size = Path(master_path).stat().st_size
            print(f"\nğŸ¯ ë§ˆìŠ¤í„° íŒŒì¼:")
            print(f"  ğŸ“Š kdca_master_dataset.csv ({master_size:,} bytes)")
        
        print(f"\nâœ… ë‹¤ìŒ ë‹¨ê³„:")
        print(f"  - ë°ì´í„° ì •ì œ ë° ë¶„ì„")
        print(f"  - ë³‘ë¬´ì²­ ë°ì´í„°ì™€ í†µí•©")
        print(f"  - íŒ¬ë°ë¯¹ ì˜í–¥ë„ ë¶„ì„")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    converter = KDCAEncodingFixer()
    
    # 1. ê°œë³„ ì—°ë„ ë³€í™˜
    converted_files = converter.convert_all_years()
    
    if converted_files:
        # 2. ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„±
        master_df = converter.create_master_dataset()
        
        # 3. ìš”ì•½ ë³´ê³ ì„œ
        converter.create_summary_report()
        
        return master_df
    else:
        print("âŒ ë³€í™˜ ì‹¤íŒ¨")
        return None

if __name__ == "__main__":
    main()