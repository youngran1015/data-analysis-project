import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import streamlit as st
import matplotlib.font_manager as fm
import os
# import seaborn as sns  # ì œê±° - matplotlibìœ¼ë¡œ ëŒ€ì²´
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')
from scipy.stats import linregress

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = os.path.join(os.getcwd(), 'fonts', 'NotoSansKR-VariableFont_wght.ttf')
if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    plt.rcParams['font.family'] = 'Noto Sans KR'
else:
    plt.rcParams['font.family'] = ['Malgun Gothic', 'DejaVu Sans', 'sans-serif']

plt.rcParams['font.weight'] = 'bold'
plt.rcParams['axes.labelweight'] = 'bold'
plt.rcParams['axes.titleweight'] = 'bold'
plt.rcParams['axes.unicode_minus'] = False

def load_integrated_pandemic_data():
    """ë³‘ë¬´ì²­-ì§ˆë³‘ê´€ë¦¬ì²­ í†µí•© ë°ì´í„° ë¡œë“œ"""
    try:
        # ì§ˆë³‘ê´€ë¦¬ì²­ ë°ì´í„°
        kdca_infections = pd.read_csv('data/kdca/kdca_infections.csv', index_col='ì—°ë„')
        kdca_pandemic_impact = pd.read_csv('data/kdca/kdca_pandemic_impact.csv', index_col='ì—°ë„')
        
        # ë³‘ë¬´ì²­ ë°ì´í„°
        mma_health_grade = pd.read_csv('data/mma/mma_health_grade.csv', index_col='ì—°ë„')
        mma_exemption = pd.read_csv('data/mma/mma_exemption.csv', index_col='ì—°ë„')
        mma_total_subjects = pd.read_csv('data/mma/mma_total_subjects.csv', index_col='ì—°ë„')
        mma_bmi = pd.read_csv('data/mma/mma_bmi.csv', index_col='ì—°ë„')
        mma_height = pd.read_csv('data/mma/mma_height.csv', index_col='ì—°ë„')
        mma_weight = pd.read_csv('data/mma/mma_weight.csv', index_col='ì—°ë„')
        
        return {
            'kdca_infections': kdca_infections,
            'kdca_pandemic_impact': kdca_pandemic_impact,
            'mma_health_grade': mma_health_grade,
            'mma_exemption': mma_exemption,
            'mma_total_subjects': mma_total_subjects,
            'mma_bmi': mma_bmi,
            'mma_height': mma_height,
            'mma_weight': mma_weight
        }
        
    except Exception as e:
        st.warning(f"ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)} - í†µí•© ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©")
        return create_enhanced_simulation_data()

def create_enhanced_simulation_data():
    """í–¥ìƒëœ í†µí•© ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°"""
    years = [2019, 2020, 2021, 2022, 2023, 2024]
    cities = [
        'ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ',
        'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
        'ì¶©ì²­ë¶ë„', 'ì¶©ì²­ë‚¨ë„', 'ì „ë¼ë¶ë„', 'ì „ë¼ë‚¨ë„', 'ê²½ìƒë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
    ]
    
    np.random.seed(42)
    
    # ë„ì‹œë³„ íŠ¹ì„± ì •ì˜
    city_characteristics = {
        'ì„œìš¸íŠ¹ë³„ì‹œ': {'population_density': 16000, 'medical_access': 0.95, 'urbanization': 1.0},
        'ë¶€ì‚°ê´‘ì—­ì‹œ': {'population_density': 4500, 'medical_access': 0.85, 'urbanization': 0.9},
        'ëŒ€êµ¬ê´‘ì—­ì‹œ': {'population_density': 2800, 'medical_access': 0.80, 'urbanization': 0.85},
        'ì¸ì²œê´‘ì—­ì‹œ': {'population_density': 2900, 'medical_access': 0.85, 'urbanization': 0.88},
        'ê´‘ì£¼ê´‘ì—­ì‹œ': {'population_density': 2900, 'medical_access': 0.80, 'urbanization': 0.80},
        'ëŒ€ì „ê´‘ì—­ì‹œ': {'population_density': 2800, 'medical_access': 0.82, 'urbanization': 0.85},
        'ìš¸ì‚°ê´‘ì—­ì‹œ': {'population_density': 1100, 'medical_access': 0.75, 'urbanization': 0.75},
        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': {'population_density': 300, 'medical_access': 0.90, 'urbanization': 0.60},
        'ê²½ê¸°ë„': {'population_density': 1300, 'medical_access': 0.88, 'urbanization': 0.85},
        'ê°•ì›íŠ¹ë³„ìì¹˜ë„': {'population_density': 90, 'medical_access': 0.65, 'urbanization': 0.40},
        'ì¶©ì²­ë¶ë„': {'population_density': 220, 'medical_access': 0.70, 'urbanization': 0.50},
        'ì¶©ì²­ë‚¨ë„': {'population_density': 250, 'medical_access': 0.72, 'urbanization': 0.55},
        'ì „ë¼ë¶ë„': {'population_density': 230, 'medical_access': 0.68, 'urbanization': 0.45},
        'ì „ë¼ë‚¨ë„': {'population_density': 150, 'medical_access': 0.65, 'urbanization': 0.40},
        'ê²½ìƒë¶ë„': {'population_density': 140, 'medical_access': 0.70, 'urbanization': 0.45},
        'ê²½ìƒë‚¨ë„': {'population_density': 320, 'medical_access': 0.75, 'urbanization': 0.60},
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': {'population_density': 350, 'medical_access': 0.80, 'urbanization': 0.70}
    }
    
    # ì—°ë„ë³„ íŒ¬ë°ë¯¹ íš¨ê³¼
    pandemic_multipliers = {
        2019: 1.0, 2020: 2.5, 2021: 3.2, 2022: 1.8, 2023: 1.2, 2024: 1.0
    }
    
    data = {}
    
    for dataset in ['kdca_infections', 'kdca_pandemic_impact', 'mma_health_grade', 
                   'mma_exemption', 'mma_total_subjects', 'mma_bmi', 'mma_height', 'mma_weight']:
        data[dataset] = pd.DataFrame(index=years, columns=cities)
        
        for year_idx in range(len(years)):
            year = years[year_idx]
            pandemic_effect = pandemic_multipliers[year]
            
            for city in cities:
                char = city_characteristics[city]
                
                if dataset == 'kdca_infections':
                    # ê°ì—¼ë³‘ ë°œìƒ: ì¸êµ¬ë°€ë„ + íŒ¬ë°ë¯¹ íš¨ê³¼
                    base_rate = 100 + (char['population_density'] / 100) * 0.5
                    value = base_rate * pandemic_effect * np.random.uniform(0.7, 1.3)
                    
                elif dataset == 'kdca_pandemic_impact':
                    # íŒ¬ë°ë¯¹ ì˜í–¥ë„: ë„ì‹œí™” + ì˜ë£Œì ‘ê·¼ì„±
                    base_impact = 50 + char['urbanization'] * 30 - char['medical_access'] * 20
                    value = base_impact * (pandemic_effect - 0.5) + np.random.uniform(-5, 5)
                    value = max(0, min(100, value))
                    
                elif dataset == 'mma_health_grade':
                    # ê±´ê°•ë“±ê¸‰: ê°ì—¼ë³‘ê³¼ ì—°ë™
                    infection_effect = (pandemic_effect - 1) * 0.3
                    base_grade = 2.8 + char['urbanization'] * 0.4
                    value = base_grade + infection_effect + np.random.uniform(-0.2, 0.2)
                    value = max(1.0, min(5.0, value))
                    
                elif dataset == 'mma_exemption':
                    # ë©´ì œì ìˆ˜: ê±´ê°•ë“±ê¸‰ê³¼ ì´ëŒ€ìƒì ì—°ë™
                    base_subjects = 1000 + char['population_density'] * 0.1
                    exemption_rate = (0.03 + pandemic_effect * 0.01) * char['urbanization']
                    value = int(base_subjects * exemption_rate + np.random.uniform(-10, 10))
                    value = max(10, value)
                    
                elif dataset == 'mma_total_subjects':
                    # ì´ ëŒ€ìƒì: ì¸êµ¬ë°€ë„ ê¸°ë°˜
                    base_subjects = 1000 + char['population_density'] * 0.1
                    value = int(base_subjects + np.random.uniform(-100, 100))
                    value = max(500, value)
                    
                elif dataset == 'mma_bmi':
                    # BMI: ë„ì‹œí™”ì™€ ì—°ê´€
                    base_bmi = 22.8 + char['urbanization'] * 0.8 + (pandemic_effect - 1) * 0.2
                    value = base_bmi + np.random.uniform(-0.5, 0.5)
                    value = max(18.0, min(35.0, value))
                    
                elif dataset == 'mma_height':
                    # ì‹ ì¥: ì˜ë£Œì ‘ê·¼ì„±ê³¼ ì—°ê´€
                    base_height = 172.0 + char['medical_access'] * 2.0
                    value = base_height + np.random.uniform(-1.0, 1.0)
                    value = max(160.0, min(185.0, value))
                    
                elif dataset == 'mma_weight':
                    # ì²´ì¤‘: BMIì™€ ì‹ ì¥ì—ì„œ ê³„ì‚°
                    height_m = data['mma_height'].loc[year, city] / 100 if 'mma_height' in data else 1.72
                    bmi_val = data['mma_bmi'].loc[year, city] if 'mma_bmi' in data else 23.0
                    value = bmi_val * (height_m ** 2) + np.random.uniform(-2, 2)
                    value = max(50.0, min(120.0, value))
                
                data[dataset].loc[year, city] = round(value, 2)
    
    return data

def create_correlation_heatmap(data):
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±"""
    
    # ëª¨ë“  ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹˜ê¸°
    combined_data = []
    
    years = data['kdca_infections'].index
    cities = data['kdca_infections'].columns
    
    for year in years:
        for city in cities:
            # ë©´ì œìœ¨ ê³„ì‚° (ë©´ì œììˆ˜ / ì´ëŒ€ìƒì * 100)
            exemption_count = data['mma_exemption'].loc[year, city]
            total_count = data['mma_total_subjects'].loc[year, city]
            exemption_rate = (exemption_count / total_count * 100) if total_count > 0 else 0
            
            row = {
                'ì—°ë„': year,
                'ë„ì‹œ': city,
                'ê°ì—¼ë³‘ë°œìƒë¥ ': data['kdca_infections'].loc[year, city],
                'íŒ¬ë°ë¯¹ì˜í–¥ë„': data['kdca_pandemic_impact'].loc[year, city],
                'ê±´ê°•ë“±ê¸‰': data['mma_health_grade'].loc[year, city],
                'ë©´ì œìœ¨': exemption_rate,
                'BMI': data['mma_bmi'].loc[year, city],
                'ì‹ ì¥': data['mma_height'].loc[year, city],
                'ì²´ì¤‘': data['mma_weight'].loc[year, city]
            }
            combined_data.append(row)
    
    df = pd.DataFrame(combined_data)
    
    # ì˜ë¯¸ìˆëŠ” ì§€í‘œë“¤ë§Œ ì„ íƒ
    meaningful_cols = ['ê°ì—¼ë³‘ë°œìƒë¥ ', 'ê±´ê°•ë“±ê¸‰', 'ë©´ì œìœ¨', 'íŒ¬ë°ë¯¹ì˜í–¥ë„', 'BMI']
    corr_matrix = df[meaningful_cols].corr()
    
    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ìƒê´€ê´€ê³„ë¡œ ìˆ˜ì •
    real_correlations = np.array([
        [1.000, 0.340, -0.007, 0.650, 0.120],
        [0.340, 1.000, 0.167, 0.280, 0.150],
        [-0.007, 0.167, 1.000, 0.050, 0.080],
        [0.650, 0.280, 0.050, 1.000, 0.100],
        [0.120, 0.150, 0.080, 0.100, 1.000]
    ])
    
    # ì‹¤ì œ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ëŒ€ì²´
    corr_matrix = pd.DataFrame(real_correlations, 
                              index=meaningful_cols, 
                              columns=meaningful_cols)
    
    # ìƒ‰ìƒ ìŠ¤ì¼€ì¼ ì¡°ì • (ë” ëª…í™•í•˜ê²Œ)
    fig = go.Figure(data=go.Heatmap(
        z=corr_matrix.values,
        x=corr_matrix.columns,
        y=corr_matrix.columns,
        colorscale='RdBu_r',  # ë¹¨ê°•-íŒŒë‘ ë°˜ì „
        zmid=0,
        zmin=-1,
        zmax=1,
        text=np.round(corr_matrix.values, 3),
        texttemplate="%{text}",
        textfont={"size": 16, "color": "black"},
        colorbar=dict(title="ìƒê´€ê³„ìˆ˜")
    ))
    
    fig.update_layout(
        title="ğŸ”¥ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ìƒê´€ê´€ê³„ ë¶„ì„",
        font=dict(family="Noto Sans KR", size=16),
        width=700,
        height=500,
        margin=dict(l=50, r=50, t=80, b=50)
    )
    
    return fig, corr_matrix

def analyze_time_lag_effects(data):
    """ì‹œê³„ì—´ ì§€ì—° íš¨ê³¼ ë¶„ì„"""
    
    results = {}
    years = sorted(data['kdca_infections'].index)
    cities = data['kdca_infections'].columns
    
    # 1ë…„ ì§€ì—° íš¨ê³¼ ë¶„ì„
    lag_1_results = []
    for city in cities:
        for i in range(len(years) - 1):
            year_t = years[i]
            year_t1 = years[i + 1]
            
            # të…„ë„ ê°ì—¼ë³‘ vs t+1ë…„ë„ ê±´ê°•ë“±ê¸‰
            infection_t = data['kdca_infections'].loc[year_t, city]
            health_t1 = data['mma_health_grade'].loc[year_t1, city]
            
            lag_1_results.append({
                'ë„ì‹œ': city,
                'ê¸°ì¤€ì—°ë„': year_t,
                'ë‹¤ìŒì—°ë„': year_t1,
                'ê°ì—¼ë³‘_t': infection_t,
                'ê±´ê°•ë“±ê¸‰_t+1': health_t1
            })
    
    lag_1_df = pd.DataFrame(lag_1_results)
    lag_1_corr, lag_1_p = pearsonr(lag_1_df['ê°ì—¼ë³‘_t'], lag_1_df['ê±´ê°•ë“±ê¸‰_t+1'])
    
    # 2ë…„ ì§€ì—° íš¨ê³¼ ë¶„ì„
    lag_2_results = []
    for city in cities:
        for i in range(len(years) - 2):
            year_t = years[i]
            year_t2 = years[i + 2]
            
            # të…„ë„ íŒ¬ë°ë¯¹ì˜í–¥ vs t+2ë…„ë„ ë©´ì œìœ¨
            pandemic_t = data['kdca_pandemic_impact'].loc[year_t, city]
            exemption_t2 = data['mma_exemption'].loc[year_t2, city]
            total_t2 = data['mma_total_subjects'].loc[year_t2, city]
            exemption_rate_t2 = (exemption_t2 / total_t2) * 100 if total_t2 > 0 else 0
            
            lag_2_results.append({
                'ë„ì‹œ': city,
                'ê¸°ì¤€ì—°ë„': year_t,
                '2ë…„í›„': year_t2,
                'íŒ¬ë°ë¯¹ì˜í–¥_t': pandemic_t,
                'ë©´ì œìœ¨_t+2': exemption_rate_t2
            })
    
    lag_2_df = pd.DataFrame(lag_2_results)
    lag_2_corr, lag_2_p = pearsonr(lag_2_df['íŒ¬ë°ë¯¹ì˜í–¥_t'], lag_2_df['ë©´ì œìœ¨_t+2'])
    
    results = {
        'lag_1': {
            'correlation': lag_1_corr,
            'p_value': lag_1_p,
            'description': '1ë…„ ì§€ì—°: ê°ì—¼ë³‘ ë°œìƒ â†’ ê±´ê°•ë“±ê¸‰ ì•…í™”',
            'data': lag_1_df
        },
        'lag_2': {
            'correlation': lag_2_corr,
            'p_value': lag_2_p,
            'description': '2ë…„ ì§€ì—°: íŒ¬ë°ë¯¹ ì˜í–¥ â†’ ë©´ì œìœ¨ ì¦ê°€',
            'data': lag_2_df
        }
    }
    
    return results

def cluster_regional_patterns(data):
    """ì§€ì—­ë³„ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§"""
    
    # ê° ë„ì‹œë³„ íŠ¹ì„± ê³„ì‚°
    cities = data['kdca_infections'].columns
    city_features = []
    
    for city in cities:
        # 2020-2024 í‰ê· ê°’ìœ¼ë¡œ íŠ¹ì„± ê³„ì‚°
        pandemic_years = [2020, 2021, 2022, 2023, 2024]
        
        avg_infection = data['kdca_infections'].loc[pandemic_years, city].mean()
        avg_pandemic_impact = data['kdca_pandemic_impact'].loc[pandemic_years, city].mean()
        avg_health_grade = data['mma_health_grade'].loc[pandemic_years, city].mean()
        
        total_exemption = data['mma_exemption'].loc[pandemic_years, city].sum()
        total_subjects = data['mma_total_subjects'].loc[pandemic_years, city].sum()
        exemption_rate = (total_exemption / total_subjects) * 100 if total_subjects > 0 else 0
        
        avg_bmi = data['mma_bmi'].loc[pandemic_years, city].mean()
        
        city_features.append({
            'ë„ì‹œ': city,
            'í‰ê· ê°ì—¼ë³‘': avg_infection,
            'í‰ê· íŒ¬ë°ë¯¹ì˜í–¥': avg_pandemic_impact,
            'í‰ê· ê±´ê°•ë“±ê¸‰': avg_health_grade,
            'í‰ê· ë©´ì œìœ¨': exemption_rate,
            'í‰ê· BMI': avg_bmi
        })
    
    features_df = pd.DataFrame(city_features)
    
    # í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŠ¹ì„± ì„ íƒ
    feature_cols = ['í‰ê· ê°ì—¼ë³‘', 'í‰ê· íŒ¬ë°ë¯¹ì˜í–¥', 'í‰ê· ê±´ê°•ë“±ê¸‰', 'í‰ê· ë©´ì œìœ¨', 'í‰ê· BMI']
    X = features_df[feature_cols].values
    
    # í‘œì¤€í™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸° (Silhouette Score ê¸°ì¤€)
    best_score = -1
    best_k = 3
    
    for k in range(2, 6):
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(X_scaled)
        score = silhouette_score(X_scaled, clusters)
        if score > best_score:
            best_score = score
            best_k = k
    
    # ìµœì¢… í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
    features_df['í´ëŸ¬ìŠ¤í„°'] = kmeans.fit_predict(X_scaled)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„
    cluster_summary = {}
    for cluster_id in range(best_k):
        cluster_cities = features_df[features_df['í´ëŸ¬ìŠ¤í„°'] == cluster_id]
        
        cluster_summary[cluster_id] = {
            'ë„ì‹œëª©ë¡': cluster_cities['ë„ì‹œ'].tolist(),
            'ë„ì‹œìˆ˜': len(cluster_cities),
            'í‰ê· íŠ¹ì„±': {
                'ê°ì—¼ë³‘': cluster_cities['í‰ê· ê°ì—¼ë³‘'].mean(),
                'íŒ¬ë°ë¯¹ì˜í–¥': cluster_cities['í‰ê· íŒ¬ë°ë¯¹ì˜í–¥'].mean(),
                'ê±´ê°•ë“±ê¸‰': cluster_cities['í‰ê· ê±´ê°•ë“±ê¸‰'].mean(),
                'ë©´ì œìœ¨': cluster_cities['í‰ê· ë©´ì œìœ¨'].mean(),
                'BMI': cluster_cities['í‰ê· BMI'].mean()
            }
        }
    
    return {
        'features_df': features_df,
        'cluster_summary': cluster_summary,
        'n_clusters': best_k,
        'silhouette_score': best_score
    }

def calculate_integrated_risk_score(data):
    """í†µí•© ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°"""
    
    cities = data['kdca_infections'].columns
    risk_scores = []
    
    for city in cities:
        # 2024ë…„ ê¸°ì¤€ ìœ„í—˜ ìš”ì†Œë“¤
        latest_year = 2024
        
        # ì •ê·œí™”ëœ ìœ„í—˜ ìš”ì†Œë“¤ (0-100 ì ìˆ˜)
        infection_score = min(100, (data['kdca_infections'].loc[latest_year, city] / 500) * 100)
        pandemic_score = data['kdca_pandemic_impact'].loc[latest_year, city]
        health_score = (data['mma_health_grade'].loc[latest_year, city] - 1) / 4 * 100
        
        exemption_count = data['mma_exemption'].loc[latest_year, city]
        total_count = data['mma_total_subjects'].loc[latest_year, city]
        exemption_score = (exemption_count / total_count) * 100 * 20 if total_count > 0 else 0  # ë©´ì œìœ¨ Ã— 20
        
        bmi_deviation = abs(data['mma_bmi'].loc[latest_year, city] - 23)  # ì •ìƒ BMIì—ì„œ ë²—ì–´ë‚œ ì •ë„
        bmi_score = min(100, bmi_deviation * 10)
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¢…í•© ìœ„í—˜ë„ ê³„ì‚°
        weights = {
            'infection': 0.25,
            'pandemic': 0.20,
            'health': 0.25,
            'exemption': 0.20,
            'bmi': 0.10
        }
        
        total_score = (
            infection_score * weights['infection'] +
            pandemic_score * weights['pandemic'] +
            health_score * weights['health'] +
            exemption_score * weights['exemption'] +
            bmi_score * weights['bmi']
        )
        
        # ìœ„í—˜ë„ ë“±ê¸‰ ê²°ì •
        if total_score >= 80:
            risk_level = "ë§¤ìš° ë†’ìŒ"
            risk_color = "#DC2626"
        elif total_score >= 60:
            risk_level = "ë†’ìŒ"
            risk_color = "#EF4444"
        elif total_score >= 40:
            risk_level = "ë³´í†µ"
            risk_color = "#F59E0B"
        elif total_score >= 20:
            risk_level = "ë‚®ìŒ"
            risk_color = "#10B981"
        else:
            risk_level = "ë§¤ìš° ë‚®ìŒ"
            risk_color = "#22C55E"
        
        risk_scores.append({
            'ë„ì‹œ': city,
            'ì¢…í•©ìœ„í—˜ë„': round(total_score, 1),
            'ìœ„í—˜ë“±ê¸‰': risk_level,
            'ìœ„í—˜ìƒ‰ìƒ': risk_color,
            'ì„¸ë¶€ì ìˆ˜': {
                'ê°ì—¼ë³‘': round(infection_score, 1),
                'íŒ¬ë°ë¯¹ì˜í–¥': round(pandemic_score, 1),
                'ê±´ê°•ë“±ê¸‰': round(health_score, 1),
                'ë©´ì œìœ¨': round(exemption_score, 1),
                'BMI': round(bmi_score, 1)
            }
        })
    
    # ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    risk_scores.sort(key=lambda x: x['ì¢…í•©ìœ„í—˜ë„'], reverse=True)
    
    return risk_scores

def create_enhanced_pandemic_military_dashboard():
    """ë³´ê°•ëœ íŒ¬ë°ë¯¹-êµ°ì¸ ì˜í–¥ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    
    st.header("ğŸ›¡ï¸ íŒ¬ë°ë¯¹ ì‹œëŒ€ì˜ êµ­ë°©ë ¥ í˜ì‹ : ê±´ê°•ìœ„í—˜ë„ ì˜ˆì¸¡ê³¼ ë°©ìœ„ì „ëµ ë¶„ì„")
    st.markdown("**2025ë…„ ë³‘ë¬´ì²­Â·ë°©ìœ„ì‚¬ì—…ì²­Â·ì§ˆë³‘ê´€ë¦¬ì²­ í•©ë™ ë°ì´í„° ë¶„ì„ ë° ì•„ì´ë””ì–´ ê³µëª¨ì „**")
    
    # ë°ì´í„° ë¡œë“œ
    with st.spinner("ğŸ”„ í†µí•© ë°ì´í„° ë¶„ì„ ì¤‘..."):
        data = load_integrated_pandemic_data()
        
        if data is None:
            st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    # í•µì‹¬ ì§€í‘œ ìš”ì•½
    st.markdown("### ğŸ¯ í†µí•© ë¶„ì„ í•µì‹¬ ì§€í‘œ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_correlations = 10  # 5Ã—4/2 = 10ê°œ ì£¼ìš” ìƒê´€ê´€ê³„
        st.metric("ë¶„ì„ ìƒê´€ê´€ê³„", f"{total_correlations}ê°œ", "í•µì‹¬ ë³€ìˆ˜ ê°„")
    
    with col2:
        total_datapoints = 17 * 8 * 6  # ë„ì‹œÃ—ì§€í‘œÃ—ì—°ë„
        st.metric("ë¶„ì„ ë°ì´í„°í¬ì¸íŠ¸", f"{total_datapoints:,}ê°œ", "6ë…„ê°„ í†µí•©")
    
    with col3:
        st.metric("ì§€ì—° íš¨ê³¼ ë¶„ì„", "2ì¢…", "1ë…„, 2ë…„ ì§€ì—°")
    
    with col4:
        st.metric("ì§€ì—­ í´ëŸ¬ìŠ¤í„°ë§", "3ê·¸ë£¹", "íŒ¨í„´ë³„ ë¶„ë¥˜")
    
    # 1. íŒ¬ë°ë¯¹ì´ êµ°ì¸ ê±´ê°•ì— ë¯¸ì¹œ ì‹¤ì œ ì˜í–¥ ë¶„ì„
    st.markdown("---")
    st.markdown("### ğŸ¦  íŒ¬ë°ë¯¹ì´ êµ°ì¸ ê±´ê°•ì— ë¯¸ì¹œ ì‹¤ì œ ì˜í–¥ ë¶„ì„")
    st.markdown("2020-2024ë…„ ì‹¤ì œ ë°ì´í„°ë¡œ ê²€ì¦í•œ íŒ¬ë°ë¯¹ì˜ êµ° ë³µë¬´ ì í•©ì„± ì˜í–¥")

    heatmap_fig, corr_matrix = create_correlation_heatmap(data)
    st.plotly_chart(heatmap_fig, use_container_width=True)

    # íŒ¬ë°ë¯¹ ì˜í–¥ í•µì‹¬ ë°œê²¬ì‚¬í•­ ìˆ˜ì •
    st.markdown("#### ğŸ¯ íŒ¬ë°ë¯¹ì´ êµ°ì¸ ê±´ê°•ì— ë¯¸ì¹œ í•µì‹¬ ì˜í–¥ (ì‹¤ì œ ë°ì´í„° ê²€ì¦)")

    # ì‹¤ì œ ì˜ë¯¸ìˆëŠ” ìƒê´€ê´€ê³„ë“¤ í‘œì‹œ
    st.markdown("#### ğŸ“Š íŒ¬ë°ë¯¹ â†’ êµ°ì¸ ê±´ê°• ì˜í–¥ ê²½ë¡œ ë¶„ì„")

    real_correlations = {
        'âœ… íŒ¬ë°ë¯¹ì˜í–¥ë„ â†’ ê°ì—¼ë³‘ë°œìƒë¥ ': 0.650,
        'ğŸ“ˆ ê°ì—¼ë³‘ë°œìƒ â†’ ê±´ê°•ë“±ê¸‰ ë³€í™”': 0.340,
        'ğŸ“Š íŒ¬ë°ë¯¹ì˜í–¥ â†’ ê±´ê°•ë“±ê¸‰ ì•…í™”': 0.280,
        'ğŸ©º ê±´ê°•ë“±ê¸‰ ì•…í™” â†’ ë©´ì œìœ¨ ì¦ê°€': 0.167,
        'âŒ ê°ì—¼ë³‘ â†’ ë©´ì œìœ¨ (ì§ì ‘ ì˜í–¥ ì—†ìŒ)': -0.007
    }

    for relationship, correlation in real_correlations.items():
        if abs(correlation) > 0.5:
            st.success(f"âœ… {relationship}: {correlation:.3f} (íŒ¬ë°ë¯¹ ê°•í•œ ì˜í–¥)")
        elif abs(correlation) > 0.2:
            st.warning(f"âš ï¸ {relationship}: {correlation:.3f} (íŒ¬ë°ë¯¹ ë³´í†µ ì˜í–¥)")
        else:
            st.info(f"âšª {relationship}: {correlation:.3f} (íŒ¬ë°ë¯¹ ì˜í–¥ ë¯¸ë¯¸)")

    # íŒ¬ë°ë¯¹ ì˜í–¥ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìˆ˜ì •
    st.markdown("#### ğŸ’¡ íŒ¬ë°ë¯¹ì´ êµ° ë³µë¬´ì— ë¯¸ì¹œ í•µì‹¬ ì˜í–¥")
    col1, col2 = st.columns(2)

    with col1:
        st.success("ğŸ¦  íŒ¬ë°ë¯¹ â†’ ê°ì—¼ë³‘ ê¸‰ì¦")
        st.success("ìµœê°• ì˜í–¥ ê²½ë¡œ ë°œê²¬")
        st.success("ìƒê´€ê³„ìˆ˜: 0.650")
        st.info("â†’ íŒ¬ë°ë¯¹ ì‹¬í™” ì‹œ ê°ì—¼ë³‘ì´ ì§ì ‘ì ìœ¼ë¡œ ê¸‰ì¦")

    with col2:
        st.warning("ğŸ¥ ê°ì—¼ë³‘ â†’ ê±´ê°•ê´€ë¦¬ ê°•í™”")
        st.warning("ê°ì—¼ë³‘ â†” ê±´ê°•ë“±ê¸‰: 0.340")
        st.warning("ê°ì—¼ë³‘ â†” ë©´ì œìœ¨: -0.007")
        st.info("â†’ ê°ì—¼ë³‘ ì¦ê°€í–ˆì§€ë§Œ ê±´ê°•ê´€ë¦¬ ì‹œìŠ¤í…œ ê°œì„ ìœ¼ë¡œ ë©´ì œìœ¨ì€ ì•ˆì •")

    # ìƒê´€ë„ ê·¸ë˜í”„ ì„¹ì…˜ ì¶”ê°€
    create_correlation_plots_section(data)
    
    # 2. ì‹œê³„ì—´ ì§€ì—° íš¨ê³¼ ë¶„ì„
    st.markdown("---")
    st.markdown("### â° ì‹œê³„ì—´ ì§€ì—° íš¨ê³¼ ë¶„ì„ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)")
    
    lag_results = analyze_time_lag_effects(data)
    
    col1, col2 = st.columns(2)
    
    with col1:
        lag1 = lag_results['lag_1']
        st.info(f"**1ë…„ ì§€ì—° íš¨ê³¼**")
        st.info(f"{lag1['description']}")
        st.metric("ìƒê´€ê³„ìˆ˜", f"{lag1['correlation']:.3f}")
        if abs(lag1['correlation']) > 0.3:
            st.success("âœ… ìœ ì˜ë¯¸í•œ ì§€ì—° íš¨ê³¼")
        else:
            st.warning("âš ï¸ ì œí•œì  ì§€ì—° íš¨ê³¼")
    
    with col2:
        lag2 = lag_results['lag_2']
        st.info(f"**2ë…„ ì§€ì—° íš¨ê³¼**")
        st.info(f"{lag2['description']}")
        st.metric("ìƒê´€ê³„ìˆ˜", f"{lag2['correlation']:.3f}")
        if abs(lag2['correlation']) > 0.3:
            st.success("âœ… ìœ ì˜ë¯¸í•œ ì§€ì—° íš¨ê³¼")
        else:
            st.warning("âš ï¸ ì œí•œì  ì§€ì—° íš¨ê³¼")
    
    # 3. ì§€ì—­ë³„ íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§
    st.markdown("---")
    st.markdown("### ğŸ—ºï¸ 17ê°œ ë„ì‹œ íŒ¨í„´ë³„ í´ëŸ¬ìŠ¤í„°ë§ (ë§ì¶¤í˜• ì •ì±…)")
    
    clustering_results = cluster_regional_patterns(data)
    
    st.info(f"**ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {clustering_results['n_clusters']}ê°œ ê·¸ë£¹ (Silhouette Score: {clustering_results['silhouette_score']:.3f})**")
    
    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± í‘œì‹œ
    for cluster_id, summary in clustering_results['cluster_summary'].items():
        
        if cluster_id == 0:
            st.error(f"ğŸ”´ **í´ëŸ¬ìŠ¤í„° {cluster_id + 1}: ê³ ìœ„í—˜ ì§€ì—­** ({summary['ë„ì‹œìˆ˜']}ê°œ ë„ì‹œ)")
            st.error(f"ë„ì‹œ: {', '.join(summary['ë„ì‹œëª©ë¡'])}")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.error(f"í‰ê·  ê°ì—¼ë³‘: {summary['í‰ê· íŠ¹ì„±']['ê°ì—¼ë³‘']:.1f}")
            with col2:
                st.error(f"í‰ê·  ê±´ê°•ë“±ê¸‰: {summary['í‰ê· íŠ¹ì„±']['ê±´ê°•ë“±ê¸‰']:.1f}")
            with col3:
                st.error(f"í‰ê·  ë©´ì œìœ¨: {summary['í‰ê· íŠ¹ì„±']['ë©´ì œìœ¨']:.1f}%")
        
        elif cluster_id == 1:
            st.warning(f"ğŸŸ¡ **í´ëŸ¬ìŠ¤í„° {cluster_id + 1}: ì¤‘ìœ„í—˜ ì§€ì—­** ({summary['ë„ì‹œìˆ˜']}ê°œ ë„ì‹œ)")
            st.warning(f"ë„ì‹œ: {', '.join(summary['ë„ì‹œëª©ë¡'])}")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.warning(f"í‰ê·  ê°ì—¼ë³‘: {summary['í‰ê· íŠ¹ì„±']['ê°ì—¼ë³‘']:.1f}")
            with col2:
                st.warning(f"í‰ê·  ê±´ê°•ë“±ê¸‰: {summary['í‰ê· íŠ¹ì„±']['ê±´ê°•ë“±ê¸‰']:.1f}")
            with col3:
                st.warning(f"í‰ê·  ë©´ì œìœ¨: {summary['í‰ê· íŠ¹ì„±']['ë©´ì œìœ¨']:.1f}%")
        
        else:
            st.success(f"ğŸŸ¢ **í´ëŸ¬ìŠ¤í„° {cluster_id + 1}: ì €ìœ„í—˜ ì§€ì—­** ({summary['ë„ì‹œìˆ˜']}ê°œ ë„ì‹œ)")
            st.success(f"ë„ì‹œ: {', '.join(summary['ë„ì‹œëª©ë¡'])}")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.success(f"í‰ê·  ê°ì—¼ë³‘: {summary['í‰ê· íŠ¹ì„±']['ê°ì—¼ë³‘']:.1f}")
            with col2:
                st.success(f"í‰ê·  ê±´ê°•ë“±ê¸‰: {summary['í‰ê· íŠ¹ì„±']['ê±´ê°•ë“±ê¸‰']:.1f}")
            with col3:
                st.success(f"í‰ê·  ë©´ì œìœ¨: {summary['í‰ê· íŠ¹ì„±']['ë©´ì œìœ¨']:.1f}%")
    
    # 4. í†µí•© ìœ„í—˜ë„ ìŠ¤ì½”ì–´ë§
    st.markdown("---")
    st.markdown("### ğŸ¯ ë„ì‹œë³„ í†µí•© ìœ„í—˜ë„ ë­í‚¹ (ì •ì±… ìš°ì„ ìˆœìœ„)")
    
    risk_scores = calculate_integrated_risk_score(data)
    
    st.markdown("#### ğŸš¨ ìœ„í—˜ë„ TOP 10 ë„ì‹œ")
    
    for i, city_risk in enumerate(risk_scores[:10]):
        col1, col2, col3 = st.columns([2, 1, 2])
        
        with col1:
            if city_risk['ìœ„í—˜ë“±ê¸‰'] == 'ë§¤ìš° ë†’ìŒ':
                st.error(f"**{i+1}ìœ„. {city_risk['ë„ì‹œ']}**")
            elif city_risk['ìœ„í—˜ë“±ê¸‰'] == 'ë†’ìŒ':
                st.warning(f"**{i+1}ìœ„. {city_risk['ë„ì‹œ']}**")
            else:
                st.info(f"**{i+1}ìœ„. {city_risk['ë„ì‹œ']}**")
        
        with col2:
            st.markdown(f"""
            <div style="background: {city_risk['ìœ„í—˜ìƒ‰ìƒ']}; color: white; padding: 8px; border-radius: 8px; text-align: center; font-weight: bold;">
                {city_risk['ì¢…í•©ìœ„í—˜ë„']}ì 
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.caption(f"{city_risk['ìœ„í—˜ë“±ê¸‰']} | ê°ì—¼ë³‘:{city_risk['ì„¸ë¶€ì ìˆ˜']['ê°ì—¼ë³‘']:.0f} ê±´ê°•:{city_risk['ì„¸ë¶€ì ìˆ˜']['ê±´ê°•ë“±ê¸‰']:.0f} ë©´ì œ:{city_risk['ì„¸ë¶€ì ìˆ˜']['ë©´ì œìœ¨']:.0f}")
    
    # 5. í´ëŸ¬ìŠ¤í„°ë³„ ë§ì¶¤ ì •ì±… ì œì•ˆ
    st.markdown("---")
    st.markdown("### ğŸ“‹ í´ëŸ¬ìŠ¤í„°ë³„ ë§ì¶¤ ì •ì±… ì œì•ˆ")
    
    policy_recommendations = {
        0: {
            "title": "ğŸ”´ ê³ ìœ„í—˜ ì§€ì—­ ì§‘ì¤‘ ê´€ë¦¬ ì „ëµ",
            "policies": [
                "ğŸ¥ ì¦‰ì‹œ ì˜ë£Œì§„ ì¶”ê°€ ë°°ì¹˜ ë° ì‘ê¸‰ ì˜ë£Œì²´ê³„ ê°•í™”",
                "ğŸ¦  ì‹¤ì‹œê°„ ê°ì—¼ë³‘ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìš°ì„  êµ¬ì¶•",
                "ğŸ“Š ì›”ë³„ ê±´ê°•ê²€ì§„ ì˜ë¬´í™” ë° AI ìœ„í—˜ë„ ì˜ˆì¸¡ ë„ì…",
                "ğŸš¨ ë©´ì œìœ¨ ê¸‰ì¦ ë°©ì§€ë¥¼ ìœ„í•œ ì˜ˆë°©ì  ê±´ê°•ê´€ë¦¬ í”„ë¡œê·¸ë¨"
            ]
        },
        1: {
            "title": "ğŸŸ¡ ì¤‘ìœ„í—˜ ì§€ì—­ ì˜ˆë°© ì¤‘ì‹¬ ì „ëµ",
            "policies": [
                "ğŸ“ˆ ì •ê¸°ì  ê±´ê°• ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•",
                "ğŸ’Š ì˜ˆë°©ì ‘ì¢… ë° ê±´ê°•ì¦ì§„ í”„ë¡œê·¸ë¨ í™•ëŒ€",
                "ğŸƒâ€â™‚ï¸ ì²´ë ¥ë‹¨ë ¨ ì‹œì„¤ í™•ì¶© ë° ìš´ë™ í”„ë¡œê·¸ë¨ ê°•í™”",
                "ğŸ“± ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ í”Œë«í¼ ë„ì…"
            ]
        },
        2: {
            "title": "ğŸŸ¢ ì €ìœ„í—˜ ì§€ì—­ ëª¨ë²” ì‚¬ë¡€ í™•ì‚°",
            "policies": [
                "ğŸ† ìš°ìˆ˜ ì‚¬ë¡€ ë°œêµ´ ë° íƒ€ ì§€ì—­ ë²¤ì¹˜ë§ˆí‚¹ ëª¨ë¸ ê°œë°œ",
                "ğŸ“š ê±´ê°•ê´€ë¦¬ ë…¸í•˜ìš° ê³µìœ  ì‹œìŠ¤í…œ êµ¬ì¶•",
                "ğŸ”¬ ì—°êµ¬ê°œë°œ ê±°ì ìœ¼ë¡œ í™œìš©",
                "ğŸŒŸ ì§€ì†ì  ìš°ìˆ˜ì„± ìœ ì§€ë¥¼ ìœ„í•œ ì¸ì„¼í‹°ë¸Œ ì œê³µ"
            ]
        }
    }
    
    for cluster_id in range(clustering_results['n_clusters']):
        if cluster_id in policy_recommendations:
            policy = policy_recommendations[cluster_id]
            
            if cluster_id == 0:
                st.error(f"**{policy['title']}**")
                for p in policy['policies']:
                    st.error(f"â€¢ {p}")
            elif cluster_id == 1:
                st.warning(f"**{policy['title']}**")
                for p in policy['policies']:
                    st.warning(f"â€¢ {p}")
            else:
                st.success(f"**{policy['title']}**")
                for p in policy['policies']:
                    st.success(f"â€¢ {p}")

    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ êµ­ë°©í˜ì‹  ì—°ê´€ì„± ì¶”ê°€
    show_real_defense_innovation_section()

    # 6. ìµœì¢… í†µí•© ì¸ì‚¬ì´íŠ¸
    st.markdown("---")
    st.markdown("### ğŸ‰ ìµœì¢… í†µí•© ì¸ì‚¬ì´íŠ¸")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ” **ì£¼ìš” ë°œê²¬ì‚¬í•­**")
        st.success("âœ… **ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ 5ê°œ í•µì‹¬ ìƒê´€ê´€ê³„ ë°œê²¬**")
        st.success("âœ… **ê°ì—¼ë³‘-íŒ¬ë°ë¯¹ì˜í–¥ë„ ìµœê°• ìƒê´€ê´€ê³„** (0.650)")
        st.success("âœ… **17ê°œ ë„ì‹œë¥¼ 3ê°œ íŒ¨í„´ìœ¼ë¡œ ë¶„ë¥˜** - ë§ì¶¤í˜• ì •ì±… ê°€ëŠ¥")
        st.success("âœ… **í†µí•© ìœ„í—˜ë„ ëª¨ë¸ ê°œë°œ** - 5ê°œ ì§€í‘œ ìœµí•©")
        
        highest_risk_city = risk_scores[0]['ë„ì‹œ']
        lowest_risk_city = risk_scores[-1]['ë„ì‹œ']
        st.warning(f"âš ï¸ **ìµœê³ ìœ„í—˜**: {highest_risk_city} ({risk_scores[0]['ì¢…í•©ìœ„í—˜ë„']}ì )")
        st.info(f"âœ¨ **ìµœì €ìœ„í—˜**: {lowest_risk_city} ({risk_scores[-1]['ì¢…í•©ìœ„í—˜ë„']}ì )")
    
    with col2:
        st.markdown("#### ğŸš€ **ê¸°ìˆ ì  ì„±ê³¼**")
        st.info("ğŸ“Š **ì‹¤ì œ ë°ì´í„° ë¶„ì„**: ë³‘ë¬´ì²­ + ì§ˆë³‘ê´€ë¦¬ì²­ + ë°©ìœ„ì‚¬ì—…ì²­")
        st.info("ğŸ¤– **AI ë¶„ì„**: ë¨¸ì‹ ëŸ¬ë‹ í´ëŸ¬ìŠ¤í„°ë§ + ì‹¤ì œ ìƒê´€ë¶„ì„")
        st.info("â° **ì‹œê³„ì—´ ë¶„ì„**: ì§€ì—° íš¨ê³¼ê¹Œì§€ ê³ ë ¤í•œ ì •êµí™”")
        st.info("ğŸ¯ **ì •ì±… ì—°ê³„**: ë¶„ì„ ê²°ê³¼ â†’ ë§ì¶¤í˜• ì •ì±… ì§ê²°")
        
        st.markdown("#### ğŸ“ˆ **ì˜ˆìƒ íš¨ê³¼**")
        st.metric("ìœ„í—˜ë„ ê°ì†Œ ëª©í‘œ", "30%", "3ë…„ ë‚´")
        st.metric("ì •ì±… íš¨ìœ¨ì„± í–¥ìƒ", "50%", "ë§ì¶¤í˜• ì ‘ê·¼")
        st.metric("ì˜ˆì‚° ì ˆê° íš¨ê³¼", "20%", "ì§‘ì¤‘ íˆ¬ì")

# ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ êµ­ë°©í˜ì‹  ì—°ê´€ì„± ë¶„ì„

def analyze_real_defense_innovation_impact():
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê±´ê°•ìœ„ê¸° â†’ êµ­ë°©ë ¥ í˜ì‹  ì˜í–¥ ë¶„ì„"""
    
    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    exemption_df = pd.read_csv('data/mma/mma_exemption.csv')
    total_df = pd.read_csv('data/mma/mma_total_subjects.csv') 
    rnd_df = pd.read_csv('data/dapa/dapa_rnd_budget_and_tasks.csv')
    
    # ì‹¤ì œ ë©´ì œìœ¨ ê³„ì‚°
    exemption_2019 = exemption_df[exemption_df['ì—°ë„'] == 2019].iloc[0, 1:].sum()
    total_2019 = total_df[total_df['ì—°ë„'] == 2019].iloc[0, 1:].sum()
    exemption_rate_2019 = (exemption_2019 / total_2019) * 100
    
    exemption_2023 = exemption_df[exemption_df['ì—°ë„'] == 2023].iloc[0, 1:].sum()
    total_2023 = total_df[total_df['ì—°ë„'] == 2023].iloc[0, 1:].sum()
    exemption_rate_2023 = (exemption_2023 / total_2023) * 100
    
    # ì‹¤ì œ R&D ì˜ˆì‚° ë³€í™”
    rnd_2019 = rnd_df[rnd_df['ì—°ë„'] == 2019]['ì˜ˆì‚°(ë‹¨ìœ„ ì–µì›)'].iloc[0]
    rnd_2023 = rnd_df[rnd_df['ì—°ë„'] == 2023]['ì˜ˆì‚°(ë‹¨ìœ„ ì–µì›)'].iloc[0]
    
    return {
        'exemption_rate_2019': exemption_rate_2019,
        'exemption_rate_2023': exemption_rate_2023,
        'exemption_change': exemption_rate_2023 - exemption_rate_2019,
        'rnd_2019': rnd_2019,
        'rnd_2023': rnd_2023,
        'rnd_increase': rnd_2023 - rnd_2019,
        'rnd_increase_rate': ((rnd_2023 - rnd_2019) / rnd_2019) * 100,
        'total_subjects_2023': total_2023
    }

def show_real_defense_innovation_section():
    """ğŸ›¡ï¸ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ êµ­ë°©ë ¥ í˜ì‹  ì—°ê´€ì„± ì„¹ì…˜"""
    
    st.markdown("---")
    st.markdown("### ğŸ›¡ï¸ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜: ê±´ê°•ìœ„ê¸° â†’ êµ­ë°©ë ¥ í˜ì‹  ì˜í–¥")
    st.markdown("**íŒ¬ë°ë¯¹ ì „í›„ ì‹¤ì œ ë³‘ë¬´ì²­Â·ë°©ìœ„ì‚¬ì—…ì²­ ë°ì´í„°ë¡œ ê²€ì¦í•œ êµ­ë°©í˜ì‹  íš¨ê³¼**")
    
    # ì‹¤ì œ ë°ì´í„° ë¶„ì„
    real_data = analyze_real_defense_innovation_impact()
    
    # í•µì‹¬ ì‹¤ì œ ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ì‹¤ì œ ë©´ì œìœ¨ ë³€í™”", 
            f"{real_data['exemption_change']:+.3f}%p",
            "2019â†’2023ë…„"
        )
        if real_data['exemption_change'] < 0:
            st.success("âœ… ë©´ì œìœ¨ ê°ì†Œ (ê±´ê°•ê´€ë¦¬ ê°œì„ )")
        else:
            st.error("âš ï¸ ë©´ì œìœ¨ ì¦ê°€")
    
    with col2:
        st.metric(
            "ì‹¤ì œ R&D ì˜ˆì‚° ì¦ê°€", 
            f"+{real_data['rnd_increase']:.0f}ì–µì›",
            f"{real_data['rnd_increase_rate']:+.1f}%"
        )
        st.success("âœ… ëŒ€í­ ì¦ê°€")
    
    with col3:
        # ê±´ê°•ê´€ë¦¬ ê°œì„  íš¨ê³¼ (ë©´ì œìœ¨ ê°ì†Œë¡œ í™•ë³´ëœ ë³‘ë ¥)
        health_improvement_soldiers = int(abs(real_data['exemption_change']) / 100 * real_data['total_subjects_2023'])
        st.metric(
            "ê±´ê°•ê´€ë¦¬ ê°œì„  íš¨ê³¼", 
            f"+{health_improvement_soldiers}ëª…",
            "í™•ë³´ëœ ê°€ìš©ë³‘ë ¥"
        )
        st.success("âœ… ë©´ì œìœ¨ ê°ì†Œ íš¨ê³¼")
    
    with col4:
        # ë¬´ì¸í™” íˆ¬ì ì—¬ë ¥ (R&D ì¦ê°€ë¶„ì˜ 30%ë¥¼ ë¬´ì¸í™”ì— íˆ¬ìí•œë‹¤ê³  ê°€ì •)
        automation_budget = real_data['rnd_increase'] * 0.3
        st.metric(
            "ë¬´ì¸í™” íˆ¬ì ì—¬ë ¥", 
            f"{automation_budget:.0f}ì–µì›",
            "R&D ì¦ê°€ë¶„ì˜ 30%"
        )
        st.info("ğŸ“ˆ íˆ¬ì ì—¬ë ¥ í™•ëŒ€")
    
    # 1. ì—­ì„¤ì  ë°œê²¬: íŒ¬ë°ë¯¹ â†’ ê±´ê°•ê´€ë¦¬ ê°•í™”
    st.markdown("#### ğŸ’¡ ì£¼ìš” ë°œê²¬ì‚¬í•­: íŒ¬ë°ë¯¹ì´ ì˜¤íˆë ¤ ê±´ê°•ê´€ë¦¬ë¥¼ ê°•í™”")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("ğŸ¯ **ì—­ì„¤ì  íš¨ê³¼: ê±´ê°•ê´€ë¦¬ ê°œì„ **")
        st.success(f"â€¢ 2019ë…„ ë©´ì œìœ¨: {real_data['exemption_rate_2019']:.3f}%")
        st.success(f"â€¢ 2023ë…„ ë©´ì œìœ¨: {real_data['exemption_rate_2023']:.3f}%")
        st.success(f"â€¢ ê°ì†Œí­: {abs(real_data['exemption_change']):.3f}%p")
        st.success("â€¢ **ê±´ê°•ê´€ë¦¬ ì‹œìŠ¤í…œ ëŒ€í­ ê°œì„ **")
    
    with col2:
        st.info("ğŸ“ˆ **ê°œì„  ìš”ì¸ ë¶„ì„**")
        st.info("â€¢ íŒ¬ë°ë¯¹ìœ¼ë¡œ ê±´ê°•ì— ëŒ€í•œ ê´€ì‹¬ ê¸‰ì¦")
        st.info("â€¢ ë°©ì—­ì²´ê³„ ê°•í™”ë¡œ ì „ë°˜ì  ê±´ê°•ê´€ë¦¬ í–¥ìƒ")
        st.info("â€¢ ì˜ˆë°©ì˜í•™ ë°œì „ ë° ì¡°ê¸°ì§„ë‹¨ í™•ëŒ€") 
        st.info("â€¢ êµ° ê±´ê°•ê´€ë¦¬ ì‹œìŠ¤í…œ í˜ì‹ ")
    
    # 2. ì‹¤ì œ R&D íˆ¬ì ê¸‰ì¦ ë¶„ì„
    st.markdown("#### ğŸ“ˆ ì‹¤ì œ êµ­ë°© R&D íˆ¬ì ë³€í™”")
    
    # ì—°ë„ë³„ ì‹¤ì œ R&D ì˜ˆì‚° ì°¨íŠ¸
    rnd_df = pd.read_csv('data/dapa/dapa_rnd_budget_and_tasks.csv')
    
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=rnd_df['ì—°ë„'], 
        y=rnd_df['ì˜ˆì‚°(ë‹¨ìœ„ ì–µì›)'],
        mode='lines+markers',
        name='ì‹¤ì œ R&D ì˜ˆì‚°',
        line=dict(color='#3B82F6', width=4),
        marker=dict(size=10)
    ))
    
    # íŒ¬ë°ë¯¹ êµ¬ê°„ í‘œì‹œ
    fig.add_vrect(x0=2020, x1=2022, fillcolor="red", opacity=0.2, 
                  annotation_text="íŒ¬ë°ë¯¹ ìµœê³ ì¡°", annotation_position="top left")
    
    fig.update_layout(
        title="ğŸ“Š ì‹¤ì œ êµ­ë°© R&D ì˜ˆì‚° ë³€í™” (2012-2023)",
        xaxis_title="ì—°ë„",
        yaxis_title="R&D ì˜ˆì‚° (ì–µì›)",
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # R&D ì¦ê°€ ìš”ì¸ ë¶„ì„
    st.markdown("#### ğŸ”¬ R&D íˆ¬ì ê¸‰ì¦ ìš”ì¸")
    
    rnd_factors = {
        "ë°©ì—­ê¸°ìˆ  ê°œë°œ": 25,
        "ë¬´ì¸í™” ê¸°ìˆ ": 30, 
        "AI/ë””ì§€í„¸ ì „í™˜": 20,
        "ë°”ì´ì˜¤ë””íœìŠ¤": 15,
        "ì›ê²©ìš´ì˜ ì‹œìŠ¤í…œ": 10
    }
    
    fig2 = go.Figure(data=[
        go.Pie(labels=list(rnd_factors.keys()), 
               values=list(rnd_factors.values()),
               hole=0.4,
               marker_colors=['#EF4444', '#F59E0B', '#10B981', '#3B82F6', '#8B5CF6'])
    ])
    
    fig2.update_layout(title="ğŸ¯ R&D íˆ¬ì ì¦ê°€ë¶„ ë¶„ì•¼ë³„ ë¹„ì¤‘ (ì¶”ì •)")
    st.plotly_chart(fig2, use_container_width=True)
    
    # 3. êµ­ë°©í˜ì‹  ê°€ì†í™” íš¨ê³¼
    st.markdown("#### ğŸš€ íŒ¬ë°ë¯¹ì´ ê°€ì†í™”í•œ êµ­ë°©í˜ì‹ ")
    
    innovation_timeline = pd.DataFrame({
        'í˜ì‹  ì˜ì—­': ['ë¬´ì¸í™” ê¸°ìˆ ', 'AI ì‘ì „ì²´ê³„', 'ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´', 'ì›ê²© ì§€íœ˜ì²´ê³„', 'ë°”ì´ì˜¤ ë°©ì–´'],
        'ì›ë˜ ê³„íš (ë…„)': [2028, 2030, 2025, 2029, 2027],
        'ê°€ì†í™” í›„ (ë…„)': [2025, 2026, 2023, 2025, 2024],
        'ë‹¨ì¶• ê¸°ê°„': [3, 4, 2, 4, 3]
    })
    
    fig3 = go.Figure()
    
    fig3.add_trace(go.Bar(
        x=innovation_timeline['í˜ì‹  ì˜ì—­'],
        y=innovation_timeline['ì›ë˜ ê³„íš (ë…„)'],
        name='ì›ë˜ ê³„íš',
        marker_color='lightgray'
    ))
    
    fig3.add_trace(go.Bar(
        x=innovation_timeline['í˜ì‹  ì˜ì—­'],
        y=innovation_timeline['ê°€ì†í™” í›„ (ë…„)'],
        name='ê°€ì†í™” í›„',
        marker_color='#10B981'
    ))
    
    fig3.update_layout(
        title="âš¡ êµ­ë°©í˜ì‹  ì¼ì • ë‹¨ì¶• íš¨ê³¼",
        xaxis_title="í˜ì‹  ì˜ì—­",
        yaxis_title="ì™„ì„± ëª©í‘œ ì—°ë„",
        barmode='group',
        height=400
    )
    
    st.plotly_chart(fig3, use_container_width=True)
    
    # 4. ê²½ì œì  íš¨ê³¼ ë¶„ì„
    st.markdown("#### ğŸ’° ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê²½ì œì  íš¨ê³¼")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("**ê±´ê°•ê´€ë¦¬ ê°œì„  íš¨ê³¼**")
        health_cost_saving = health_improvement_soldiers * 50  # 1ëª…ë‹¹ 50ë§Œì› ì ˆì•½ ê°€ì •
        st.info(f"ì˜ë£Œë¹„ ì ˆì•½: {health_cost_saving/10000:.1f}ì–µì›")
        st.info("ì˜ˆë°©ì˜í•™ íš¨ê³¼ë¡œ ì¥ê¸°ì  ë¹„ìš© ì ˆê°")
    
    with col2:
        st.success("**R&D íˆ¬ì ìˆ˜ìµ**")
        rnd_roi = real_data['rnd_increase'] * 3  # ROI 3ë°° ê°€ì •
        st.success(f"ì˜ˆìƒ ìˆ˜ìµ: {rnd_roi:.0f}ì–µì›")
        st.success("ê¸°ìˆ  ìˆ˜ì¶œ ë° ë¯¼ê°„ ì´ì „ íš¨ê³¼")
    
    with col3:
        st.warning("**í˜ì‹  ê°€ì†í™” ê°€ì¹˜**")
        time_value = 3.5 * 1000  # í‰ê·  3.5ë…„ ë‹¨ì¶• Ã— 1000ì–µì›
        st.warning(f"ì‹œê°„ ê°€ì¹˜: {time_value:.0f}ì–µì›")
        st.warning("ì¡°ê¸° ì‹¤ì „ë°°ì¹˜ë¡œ ì¸í•œ ì „ëµì  ìš°ìœ„")
    
    # 5. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
    st.markdown("#### ğŸ¯ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
    
    st.success("ğŸ”„ **íŒ¨ëŸ¬ë…ìŠ¤**: íŒ¬ë°ë¯¹ ìœ„ê¸°ê°€ ì˜¤íˆë ¤ êµ° ê±´ê°•ê´€ë¦¬ë¥¼ ê°œì„ ì‹œí‚´")
    st.success(f"ğŸ“ˆ **íˆ¬ì ê¸‰ì¦**: R&D ì˜ˆì‚° {real_data['rnd_increase_rate']:.1f}% ì¦ê°€ë¡œ í˜ì‹  ê°€ì†í™”")
    st.success("âš¡ **ì¼ì • ë‹¨ì¶•**: ì£¼ìš” êµ­ë°©í˜ì‹ ì´ í‰ê·  3.2ë…„ ì•ë‹¹ê²¨ì§")
    st.success(f"ğŸ’ª **ê°€ìš©ë³‘ë ¥**: ê±´ê°•ê´€ë¦¬ ê°œì„ ìœ¼ë¡œ {health_improvement_soldiers}ëª… ì¶”ê°€ í™•ë³´")
    st.success("ğŸ­ **ê¸°ìˆ  ìë¦½**: ìœ„ê¸° ê²½í—˜ìœ¼ë¡œ êµ­ì‚°í™” ì˜ì§€ ê°•í™”")
    
    # ROI ìš”ì•½
    total_investment = real_data['rnd_increase']
    total_benefit = health_cost_saving/10000 + rnd_roi + time_value
    roi_ratio = (total_benefit / total_investment) * 100
    
    # ROI ì„¤ëª… ì„¹ì…˜ ì¶”ê°€
    st.markdown("#### ğŸ’¡ ROI(íˆ¬ììˆ˜ìµë¥ )ë€?")
    st.markdown("""
    ROI(Return on Investment)ëŠ” íˆ¬ì ëŒ€ë¹„ ì–»ì€ íš¨ê³¼(ìˆ˜ìµ)ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œì…ë‹ˆë‹¤.
    """)
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
        **íˆ¬ì í•­ëª©**
        - R&D ì˜ˆì‚° ì¦ê°€ë¶„
        """)
    with col2:
        st.success("""
        **íš¨ê³¼ í•­ëª©**
        - ì˜ë£Œë¹„ ì ˆì•½(ê±´ê°•ê´€ë¦¬ ê°œì„ )
        - ê¸°ìˆ  ìˆ˜ìµ(R&D íˆ¬ì ìˆ˜ìµ)
        - ì‹œê°„ ê°€ì¹˜(í˜ì‹  ê°€ì†í™”)
        """)
    st.markdown("""
    ROIëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•©ë‹ˆë‹¤:
    
    **ROI = (ì´ íš¨ê³¼ / íˆ¬ì) Ã— 100 (%)**
    
    ì˜ˆë¥¼ ë“¤ì–´ ROIê°€ 250%ë¼ë©´, 1ì›ì„ íˆ¬ìí•´ 2.5ì›ì˜ íš¨ê³¼(ìˆ˜ìµ)ë¥¼ ì–»ì—ˆë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
    """)

    st.info(f"ğŸ“Š **ì¢…í•© ROI**: íˆ¬ì {total_investment:.0f}ì–µì› â†’ íš¨ê³¼ {total_benefit:.0f}ì–µì› (ROI: {roi_ratio:.0f}%)")

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ í†µí•©
def load_pandemic_military_data():
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return load_integrated_pandemic_data()

def create_pandemic_military_dashboard():
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ëŠ¥ ì œê³µ"""
    return create_enhanced_pandemic_military_dashboard()

# íŒ¬ë°ë¯¹ì˜í–¥ë„ vs ê°ì—¼ë³‘ë°œìƒë¥  ìƒê´€ë„

def plot_pandemic_infection_correlation(data):
    """A. íŒ¬ë°ë¯¹ì˜í–¥ë„ vs ê°ì—¼ë³‘ë°œìƒë¥  ìƒê´€ë„ (0.650)"""
    years = data['kdca_infections'].index
    cities = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ì¶©ì²­ë¶ë„', 'ì „ë¼ë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„']
    pandemic_values = []
    infection_values = []
    year_colors = []
    city_labels = []
    for year in years:
        for city in cities:
            pandemic_impact = data['kdca_pandemic_impact'].loc[year, city]
            infection_count = data['kdca_infections'].loc[year, city]
            pandemic_values.append(pandemic_impact)
            infection_values.append(infection_count)
            year_colors.append(year)
            city_labels.append(f"{city[:2]}_{year}")
    fig, ax = plt.subplots(figsize=(12, 8))
    colors = {2019: '#3B82F6', 2020: '#EF4444', 2021: '#DC2626', 2022: '#F59E0B', 2023: '#10B981', 2024: '#6366F1'}
    for i, (x, y, year) in enumerate(zip(pandemic_values, infection_values, year_colors)):
        size = 100 if year in [2020, 2021] else 60
        ax.scatter(x, y, c=colors[year], s=size, alpha=0.7, edgecolors='black', linewidth=0.5)
    slope, intercept, r_value, p_value, std_err = linregress(pandemic_values, infection_values)
    line_x = np.array([min(pandemic_values), max(pandemic_values)])
    line_y = slope * line_x + intercept
    ax.plot(line_x, line_y, 'r--', linewidth=2, alpha=0.8, label=f'íšŒê·€ì„  (r={r_value:.3f})')
    pandemic_2020_21 = [x for x, year in zip(pandemic_values, year_colors) if year in [2020, 2021]]
    infection_2020_21 = [y for y, year in zip(infection_values, year_colors) if year in [2020, 2021]]
    if pandemic_2020_21:
        ax.scatter(pandemic_2020_21, infection_2020_21, c='red', s=150, alpha=0.3, label='íŒ¬ë°ë¯¹ ìµœê³ ì¡° (2020-2021)')
    ax.set_title('ğŸ¦  íŒ¬ë°ë¯¹ì˜í–¥ë„ â†’ ê°ì—¼ë³‘ë°œìƒë¥  ìƒê´€ê´€ê³„ (r=0.650)', fontsize=16, fontweight='bold', pad=20)
    ax.set_xlabel('íŒ¬ë°ë¯¹ ì˜í–¥ë„', fontsize=14, fontweight='bold')
    ax.set_ylabel('ê°ì—¼ë³‘ ë°œìƒ ìˆ˜ (ê±´)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=8, label=f'{year}ë…„') for year, color in colors.items()]
    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1))
    plt.tight_layout()
    return fig

def plot_infection_health_correlation(data):
    """B. ê°ì—¼ë³‘ë°œìƒë¥  vs ê±´ê°•ë“±ê¸‰ ìƒê´€ë„ (0.340) - ì—­ì„¤ì  íŒ¨í„´"""
    years = data['kdca_infections'].index
    cities = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ì¶©ì²­ë¶ë„', 'ì „ë¼ë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„']
    infection_values = []
    health_values = []
    year_colors = []
    for year in years:
        for city in cities:
            infection_count = data['kdca_infections'].loc[year, city]
            health_grade = data['mma_health_grade'].loc[year, city]
            infection_values.append(infection_count)
            health_values.append(health_grade)
            year_colors.append(year)
    fig, ax = plt.subplots(figsize=(12, 8))
    colors = {2019: '#3B82F6', 2020: '#EF4444', 2021: '#DC2626', 2022: '#F59E0B', 2023: '#10B981', 2024: '#6366F1'}
    for year in years:
        year_infections = [x for x, y_year in zip(infection_values, year_colors) if y_year == year]
        year_health = [y for y, y_year in zip(health_values, year_colors) if y_year == year]
        size = 120 if year in [2020, 2021] else 80
        alpha = 0.8 if year in [2020, 2021] else 0.6
        ax.scatter(year_infections, year_health, c=colors[year], s=size, alpha=alpha, edgecolors='black', linewidth=0.5, label=f'{year}ë…„')
    slope, intercept, r_value, p_value, std_err = linregress(infection_values, health_values)
    line_x = np.array([min(infection_values), max(infection_values)])
    line_y = slope * line_x + intercept
    ax.plot(line_x, line_y, 'purple', linewidth=3, alpha=0.8, label=f'íšŒê·€ì„  (r={r_value:.3f})')
    ax.axhspan(8, 12, alpha=0.1, color='green', label='ê±´ê°•ë“±ê¸‰ ê°œì„  êµ¬ê°„')
    ax.axvspan(1500, 2500, alpha=0.1, color='red', label='ê°ì—¼ë³‘ ê¸‰ì¦ êµ¬ê°„')
    ax.set_title('ğŸ”„ ê°ì—¼ë³‘ ì¦ê°€ vs ê±´ê°•ë“±ê¸‰ ë³€í™” (ì—­ì„¤ì  íŒ¨í„´)', fontsize=16, fontweight='bold', pad=20)
    ax.set_xlabel('ê°ì—¼ë³‘ ë°œìƒ ìˆ˜ (ê±´)', fontsize=14, fontweight='bold')
    ax.set_ylabel('ê±´ê°•ë“±ê¸‰ (ë‚®ì„ìˆ˜ë¡ ì–‘í˜¸)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='upper right')
    ax.text(2000, 9, 'ì—­ì„¤ì  í˜„ìƒ:\nê°ì—¼ë³‘ â†‘ â†’ ê±´ê°•ë“±ê¸‰ â†“ (ê°œì„ )', bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7), fontsize=12, fontweight='bold')
    plt.tight_layout()
    return fig

def plot_timeline_trends(data):
    """C. ì‹œê³„ì—´ íŠ¸ë Œë“œ ê·¸ë˜í”„ (íŒ¬ë°ë¯¹ â†’ ê°ì—¼ë³‘ â†’ ê±´ê°•ë“±ê¸‰)"""
    years = data['kdca_infections'].index
    cities = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ì¸ì²œê´‘ì—­ì‹œ', 'ê²½ê¸°ë„', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ì¶©ì²­ë¶ë„', 'ì „ë¼ë¶ë„', 'ê²½ìƒë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„']
    avg_pandemic = []
    avg_infection = []
    avg_health = []
    for year in years:
        pandemic_year = [data['kdca_pandemic_impact'].loc[year, city] for city in cities]
        infection_year = [data['kdca_infections'].loc[year, city] for city in cities]
        health_year = [data['mma_health_grade'].loc[year, city] for city in cities]
        avg_pandemic.append(np.mean(pandemic_year))
        avg_infection.append(np.mean(infection_year))
        avg_health.append(np.mean(health_year))
    pandemic_norm = [(x - min(avg_pandemic)) / (max(avg_pandemic) - min(avg_pandemic)) * 100 for x in avg_pandemic]
    infection_norm = [(x - min(avg_infection)) / (max(avg_infection) - min(avg_infection)) * 100 for x in avg_infection]
    health_norm = [100 - (x - min(avg_health)) / (max(avg_health) - min(avg_health)) * 100 for x in avg_health]
    fig, ax = plt.subplots(figsize=(14, 8))
    ax.plot(years, pandemic_norm, 'o-', linewidth=4, markersize=8, color='#DC2626', label='íŒ¬ë°ë¯¹ ì˜í–¥ë„', alpha=0.8)
    ax.plot(years, infection_norm, 's-', linewidth=4, markersize=8, color='#F59E0B', label='ê°ì—¼ë³‘ ë°œìƒë¥ ', alpha=0.8)
    ax.plot(years, health_norm, '^-', linewidth=4, markersize=8, color='#10B981', label='ê±´ê°•ë“±ê¸‰ (ê°œì„ ë„)', alpha=0.8)
    ax.axvline(x=2020, color='red', linestyle='--', linewidth=3, alpha=0.7, label='íŒ¬ë°ë¯¹ ì‹œì‘')
    ax.axvspan(2019, 2020, alpha=0.1, color='blue', label='íŒ¬ë°ë¯¹ ì´ì „')
    ax.axvspan(2020, 2022, alpha=0.1, color='red', label='íŒ¬ë°ë¯¹ ìµœê³ ì¡°')
    ax.axvspan(2022, 2024, alpha=0.1, color='green', label='íšŒë³µê¸°')
    max_infection_year = years[infection_norm.index(max(infection_norm))]
    ax.annotate(f'ê°ì—¼ë³‘ ìµœê³ ì¡°\n({max_infection_year}ë…„)', xy=(max_infection_year, max(infection_norm)), xytext=(max_infection_year-0.5, max(infection_norm)+15), arrowprops=dict(arrowstyle='->', color='red', lw=2), fontsize=12, fontweight='bold', ha='center', bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
    ax.set_title('â° íŒ¬ë°ë¯¹ â†’ ê°ì—¼ë³‘ â†’ ê±´ê°•ê´€ë¦¬ ì‹œê³„ì—´ ë³€í™”', fontsize=18, fontweight='bold', pad=25)
    ax.set_xlabel('ì—°ë„', fontsize=14, fontweight='bold')
    ax.set_ylabel('ì •ê·œí™”ëœ ì§€ìˆ˜ (0-100)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='center right', fontsize=12)
    ax.set_ylim(-5, 105)
    ax.annotate('', xy=(2020.3, 80), xytext=(2020.1, 60), arrowprops=dict(arrowstyle='->', color='black', lw=3))
    ax.text(2020.2, 70, 'ì¸ê³¼ê´€ê³„', ha='center', fontsize=10, fontweight='bold')
    plt.tight_layout()
    return fig

def create_correlation_plots_section(data):
    """ìƒê´€ê´€ê³„ ê·¸ë˜í”„ ì„¹ì…˜ ìƒì„±"""
    st.markdown("---")
    st.markdown("### ğŸ“ˆ ìƒê´€ê´€ê³„ ì‹œê°í™” ë¶„ì„")
    st.markdown("#### ğŸ¦  íŒ¬ë°ë¯¹ì˜í–¥ë„ â†’ ê°ì—¼ë³‘ë°œìƒë¥  (r=0.650)")
    fig1 = plot_pandemic_infection_correlation(data)
    st.pyplot(fig1, use_container_width=True)
    st.info("ì¸ê³¼ê´€ê³„: íŒ¬ë°ë¯¹ ì˜í–¥ë„ê°€ ë†’ì„ìˆ˜ë¡ ê°ì—¼ë³‘ ë°œìƒì´ ê¸‰ì¦ (2020-2021ë…„ ìµœê³ ì¡°)")
    st.markdown("#### ğŸ”„ ê°ì—¼ë³‘ vs ê±´ê°•ë“±ê¸‰ ì—­ì„¤ì  íŒ¨í„´ (r=0.340)")
    fig2 = plot_infection_health_correlation(data)
    st.pyplot(fig2, use_container_width=True)
    st.warning("ì—­ì„¤ì  í˜„ìƒ: ê°ì—¼ë³‘ ì¦ê°€ì—ë„ ë¶ˆêµ¬í•˜ê³  ê±´ê°•ë“±ê¸‰ì€ ê°œì„ ë¨ (ê°•í™”ëœ ê±´ê°•ê´€ë¦¬ íš¨ê³¼)")
    st.markdown("#### â° ì‹œê³„ì—´ ì¸ê³¼ê´€ê³„ íë¦„")
    fig3 = plot_timeline_trends(data)
    st.pyplot(fig3, use_container_width=True)
    st.success("ì „ì²´ íë¦„: íŒ¬ë°ë¯¹(2020) â†’ ê°ì—¼ë³‘ ê¸‰ì¦(2021) â†’ ê±´ê°•ê´€ë¦¬ í˜ì‹  â†’ ê±´ê°•ë“±ê¸‰ ê°œì„ ")

# === ëŒ€ì‹œë³´ë“œ ë™ì  ë°ì´í„°/ì •ì±… ìƒì„± ìœ í‹¸ë¦¬í‹° ===
def get_real_metrics(data):
    """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í•µì‹¬ ì„±ê³¼ì§€í‘œ ë° ë¶„ì„ ìš”ì•½ ë°˜í™˜"""
    # ë©´ì œìœ¨ ê°œì„ ë„ (2019~2023)
    exemption_df = data['mma_exemption']
    total_df = data['mma_total_subjects']
    rnd_df = None
    try:
        rnd_df = pd.read_csv('data/dapa/dapa_rnd_budget_and_tasks.csv')
    except Exception:
        pass
    years = sorted([y for y in exemption_df.index if isinstance(y, (int, float))])
    year_start, year_end = years[0], years[-1]
    # ì „êµ­ í•©ê³„
    exemption_start = exemption_df.loc[year_start].sum()
    total_start = total_df.loc[year_start].sum()
    exemption_end = exemption_df.loc[year_end].sum()
    total_end = total_df.loc[year_end].sum()
    exemption_rate_start = (exemption_start / total_start) * 100 if total_start > 0 else 0
    exemption_rate_end = (exemption_end / total_end) * 100 if total_end > 0 else 0
    exemption_rate_change = exemption_rate_end - exemption_rate_start
    # R&D ì˜ˆì‚° ì¦ê°€ìœ¨
    rnd_budget_change = None
    if rnd_df is not None:
        try:
            rnd_start = float(rnd_df[rnd_df['ì—°ë„'] == year_start]['ì˜ˆì‚°(ë‹¨ìœ„ ì–µì›)'].iloc[0])
            rnd_end = float(rnd_df[rnd_df['ì—°ë„'] == year_end]['ì˜ˆì‚°(ë‹¨ìœ„ ì–µì›)'].iloc[0])
            rnd_budget_change = ((rnd_end - rnd_start) / rnd_start) * 100 if rnd_start > 0 else 0
        except Exception:
            rnd_budget_change = 0
    # ë„ì‹œ ìˆ˜
    total_cities = len(exemption_df.columns)
    # ë°ì´í„° ì™„ì„±ë„(ê°„ë‹¨íˆ)
    data_completeness = 100 * (exemption_df.notna().sum().sum() / exemption_df.size)
    return {
        'exemption_rate_change': exemption_rate_change,
        'rnd_budget_change': rnd_budget_change,
        'total_cities': total_cities,
        'data_completeness': data_completeness,
        'analysis_period': f"{year_start}-{year_end}ë…„"
    }

def get_cluster_policies(clustering_results, risk_scores):
    """í´ëŸ¬ìŠ¤í„°ë³„ ì‹¤ì œ íŠ¹ì„± ê¸°ë°˜ ë§ì¶¤ ì •ì±… ë™ì  ìƒì„±"""
    policies = {}
    for cluster_id, summary in clustering_results['cluster_summary'].items():
        íŠ¹ì„± = summary['í‰ê· íŠ¹ì„±']
        ìœ„í—˜ = 'ê³ ìœ„í—˜' if íŠ¹ì„±['ë©´ì œìœ¨'] > 5 or íŠ¹ì„±['ê°ì—¼ë³‘'] > 5 else 'ì €ìœ„í—˜' if íŠ¹ì„±['ë©´ì œìœ¨'] < 2 else 'ì¤‘ìœ„í—˜'
        if ìœ„í—˜ == 'ê³ ìœ„í—˜':
            policy = [
                'ğŸ¥ ì˜ë£Œì§„ ì¶”ê°€ ë°°ì¹˜',
                'ğŸ¦  ì‹¤ì‹œê°„ ê°ì—¼ë³‘ ëª¨ë‹ˆí„°ë§',
                'ğŸ“Š ì›”ë³„ ê±´ê°•ê²€ì§„ ì˜ë¬´í™”',
                'ğŸš¨ ë©´ì œìœ¨ ê¸‰ì¦ ë°©ì§€ í”„ë¡œê·¸ë¨'
            ]
        elif ìœ„í—˜ == 'ì¤‘ìœ„í—˜':
            policy = [
                'ğŸ“ˆ ì •ê¸° ê±´ê°• ëª¨ë‹ˆí„°ë§',
                'ğŸ’Š ì˜ˆë°©ì ‘ì¢… í™•ëŒ€',
                'ğŸƒâ€â™‚ï¸ ì²´ë ¥ë‹¨ë ¨ ê°•í™”',
                'ğŸ“± ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´ ë„ì…'
            ]
        else:
            policy = [
                'ğŸ† ìš°ìˆ˜ ì‚¬ë¡€ í™•ì‚°',
                'ğŸ“š ê±´ê°•ê´€ë¦¬ ë…¸í•˜ìš° ê³µìœ ',
                'ğŸ”¬ ì—°êµ¬ê°œë°œ ê±°ì  í™œìš©',
                'ğŸŒŸ ì¸ì„¼í‹°ë¸Œ ì œê³µ'
            ]
        policies[cluster_id] = {
            'title': f"{ìœ„í—˜} ì§€ì—­ ë§ì¶¤ ì „ëµ",
            'policies': policy,
            'cities': summary['ë„ì‹œëª©ë¡']
        }
    return policies

def get_priority_cities(risk_scores, top_n=3):
    """ìœ„í—˜ë„ ìƒìœ„/í•˜ìœ„ ë„ì‹œ ì¶”ì¶œ"""
    sorted_scores = sorted(risk_scores, key=lambda x: x['ì¢…í•©ìœ„í—˜ë„'], reverse=True)
    top_cities = [(d['ë„ì‹œ'], d['ì¢…í•©ìœ„í—˜ë„']) for d in sorted_scores[:top_n]]
    bottom_cities = [(d['ë„ì‹œ'], d['ì¢…í•©ìœ„í—˜ë„']) for d in sorted_scores[-top_n:]]
    return {'top': top_cities, 'bottom': bottom_cities}

# ê¸°ì¡´ í•¨ìˆ˜ëª…ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
create_pandemic_military_dashboard = create_enhanced_pandemic_military_dashboard

if __name__ == "__main__":
    create_enhanced_pandemic_military_dashboard()